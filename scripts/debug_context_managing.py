"""Phase 03-3: Context Managing ë””ë²„ê·¸ ìŠ¤í¬ë¦½íŠ¸

LangSmith + ì½˜ì†” ì¶œë ¥ìœ¼ë¡œ Context êµ¬ì„± í™•ì¸
"""
import os
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage

load_dotenv()

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("âŒ GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
    exit(1)

from service.react_graph import ReactGraphBuilder, extract_last_n_turns, extract_current_turn

def print_separator(title: str):
    print(f"\n{'='*60}")
    print(f"  {title}")
    print('='*60)

def print_messages(messages: list, label: str):
    print(f"\nğŸ“‹ {label} ({len(messages)}ê°œ):")
    for i, msg in enumerate(messages):
        role = msg.__class__.__name__
        content = msg.content[:50] + "..." if len(msg.content) > 50 else msg.content
        print(f"   [{i}] {role}: {content}")

def main():
    builder = ReactGraphBuilder(api_key=API_KEY, db_path=":memory:")
    builder.build()

    # ì‹œë®¬ë ˆì´ì…˜í•  ëŒ€í™” íˆìŠ¤í† ë¦¬
    conversation_history = []
    summary_history = []

    # Turn 1-7 ì‹œë®¬ë ˆì´ì…˜
    turns = [
        "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œìš”?",
        "ì„œìš¸ì˜ ì¸êµ¬ê°€ ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",
        "íŒŒì´ì¬ìœ¼ë¡œ ì›¹ í¬ë¡¤ë§í•˜ëŠ” ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
        "LangChainì´ ë­”ê°€ìš”?",
        "Reactì™€ Vue ì¤‘ ë­ê°€ ì¢‹ë‚˜ìš”?",
        "Docker ì»¨í…Œì´ë„ˆ ë§Œë“œëŠ” ë²• ì•Œë ¤ì¤˜",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ ì˜¤ëŠ˜ í•  ì¼ ì •ë¦¬í•´ì¤˜",
    ]

    for turn_num, user_input in enumerate(turns, 1):
        print_separator(f"Turn {turn_num}")
        print(f"ğŸ‘¤ User: {user_input}")

        # Context êµ¬ì„± ì‹œë®¬ë ˆì´ì…˜
        if turn_num > 1:
            # ì´ì „ í„´ë“¤ ê³„ì‚°
            summarized_turns = len(summary_history) * 3
            unsummarized_start = summarized_turns + 1
            unsummarized_count = turn_num - 1 - summarized_turns

            print(f"\nğŸ“Š Context êµ¬ì„±:")
            print(f"   - ìš”ì•½ëœ í„´: 1~{summarized_turns} ({len(summary_history)}ê°œ ìš”ì•½)")
            print(f"   - Raw í„´: {unsummarized_start}~{turn_num-1} ({unsummarized_count}ê°œ)")
            print(f"   - í˜„ì¬ í„´: {turn_num}")

            # extract í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
            raw_turns = extract_last_n_turns(conversation_history, n=unsummarized_count)
            print_messages(raw_turns, "Raw Turns (unsummarized)")

        # ì‹¤ì œ invoke ì‹¤í–‰
        result = builder.invoke(
            user_input=user_input,
            session_id=f"debug_session_{turn_num}",
            messages=conversation_history.copy(),
            turn_count=turn_num,
            compression_rate=0.3,
            summary_history=summary_history.copy(),
        )

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        conversation_history.append(HumanMessage(content=user_input))
        conversation_history.append(AIMessage(content=result.get("text", ""), tool_calls=[]))

        # summary_history ì—…ë°ì´íŠ¸
        if result.get("summary_history"):
            summary_history = result["summary_history"]

        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ¤– Assistant: {result.get('text', '')[:100]}...")

        if result.get("summary_history"):
            print(f"\nğŸ“ Summary History ({len(summary_history)}ê°œ):")
            for i, sh in enumerate(summary_history):
                print(f"   [{i}] Turns {sh['turns']}: {sh['summary'][:50]}...")
                print(f"       original: {sh['original_chars']}ì â†’ summary: {sh['summary_chars']}ì (rate: {sh['compression_rate']})")

        print(f"\nğŸ’° Tokens: input={result.get('input_tokens', 0)}, output={result.get('output_tokens', 0)}")

        # ì ì‹œ ëŒ€ê¸° (API rate limit ê³ ë ¤)
        if turn_num < len(turns):
            import time
            time.sleep(1)

    print_separator("ìµœì¢… ìƒíƒœ")
    print(f"ğŸ“‹ ì´ ë©”ì‹œì§€: {len(conversation_history)}ê°œ")
    print(f"ğŸ“ ì´ ìš”ì•½: {len(summary_history)}ê°œ")
    print("\nâœ… LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ìƒì„¸ íŠ¸ë ˆì´ìŠ¤ í™•ì¸ ê°€ëŠ¥")
    print("   https://smith.langchain.com/")

if __name__ == "__main__":
    main()
