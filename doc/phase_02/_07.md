# Phase 02-7: ê°œì„  ì‚¬í•­

## 1. Token Usage ë¯¸í‘œì‹œ ë¬¸ì œ

### í˜„ìƒ
- ì‚¬ì´ë“œë°”ì˜ "Token Usage" ì„¹ì…˜ì—ì„œ `ì…ë ¥: 0 tokens ì¶œë ¥: 0 tokens ì´ê³„: 0 tokens`ë¡œ í•­ìƒ í‘œì‹œë¨

### ì›ì¸ ë¶„ì„
- `service/react_graph.py`ì˜ `invoke()` ë©”ì„œë“œì—ì„œ LLM í˜¸ì¶œ ì‹œ í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•˜ì§€ ì•ŠìŒ
- `ChatState`ì— `input_tokens`, `output_tokens` í•„ë“œê°€ ìˆìœ¼ë‚˜ ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠìŒ
- `_llm.invoke()` í˜¸ì¶œ í›„ ì‘ë‹µì˜ í† í° ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ

### í•´ê²° ë°©ì•ˆ

#### 1.1 ReactGraphBuilder í† í° ì¶”ì  êµ¬í˜„
```python
# service/react_graph.py

def _invoke_llm_with_token_tracking(self, messages: list[BaseMessage]) -> tuple[str, int, int]:
    """LLM í˜¸ì¶œ + í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 

    Returns:
        tuple: (ì‘ë‹µ í…ìŠ¤íŠ¸, ì…ë ¥ í† í°, ì¶œë ¥ í† í°)
    """
    response = self._llm.invoke(messages)

    # LangChain ChatGoogleGenerativeAI ì‘ë‹µì—ì„œ í† í° ì •ë³´ ì¶”ì¶œ
    input_tokens = 0
    output_tokens = 0

    if hasattr(response, "usage_metadata"):
        usage = response.usage_metadata
        input_tokens = getattr(usage, "input_tokens", 0)
        output_tokens = getattr(usage, "output_tokens", 0)
    elif hasattr(response, "response_metadata"):
        metadata = response.response_metadata
        if "usage_metadata" in metadata:
            input_tokens = metadata["usage_metadata"].get("prompt_token_count", 0)
            output_tokens = metadata["usage_metadata"].get("candidates_token_count", 0)

    return response.content, input_tokens, output_tokens
```

#### 1.2 ê° ë…¸ë“œì—ì„œ í† í° ëˆ„ì 
```python
def _tool_selector_node(self, state: ChatState) -> dict:
    # ... ê¸°ì¡´ ì½”ë“œ ...

    content, in_tokens, out_tokens = self._invoke_llm_with_token_tracking(
        [HumanMessage(content=prompt)]
    )
    selected_tool = content.strip().lower()

    return {
        "current_tool": selected_tool,
        "input_tokens": state.get("input_tokens", 0) + in_tokens,
        "output_tokens": state.get("output_tokens", 0) + out_tokens,
    }
```

#### 1.3 invoke() ë°˜í™˜ê°’ì— í† í° ì •ë³´ í¬í•¨
```python
def invoke(self, ...) -> dict:
    # ... ê¸°ì¡´ ì½”ë“œ ...

    return {
        "text": result.get("final_response", ""),
        # ... ê¸°ì¡´ í•„ë“œ ...
        "input_tokens": result.get("input_tokens", 0),
        "output_tokens": result.get("output_tokens", 0),
        "total_tokens": result.get("input_tokens", 0) + result.get("output_tokens", 0),
    }
```

#### 1.4 app.pyì—ì„œ token_usage ì—…ë°ì´íŠ¸
```python
# app.py: handle_chat_message í•¨ìˆ˜

response = graph.invoke(...)

# í† í° ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
st.session_state.token_usage["input"] += response.get("input_tokens", 0)
st.session_state.token_usage["output"] += response.get("output_tokens", 0)
st.session_state.token_usage["total"] = (
    st.session_state.token_usage["input"] + st.session_state.token_usage["output"]
)
```

### ìˆ˜ì • ëŒ€ìƒ íŒŒì¼
| íŒŒì¼ | ìˆ˜ì • ë‚´ìš© |
|------|----------|
| `service/react_graph.py` | í† í° ì¶”ì  ë©”ì„œë“œ ì¶”ê°€, ê° ë…¸ë“œì—ì„œ í† í° ëˆ„ì  |
| `app.py` | `handle_chat_message`ì—ì„œ `token_usage` ì—…ë°ì´íŠ¸ |

---

## 2. ì¶”ë¡  ëª¨ë“œ (Reasoning Mode) ê¸°ëŠ¥

### ìš”êµ¬ì‚¬í•­
- ì‚¬ì´ë“œë°”ì—ì„œ ì¶”ë¡  ëª¨ë“œë¥¼ ON/OFF í•  ìˆ˜ ìˆì–´ì•¼ í•¨
- ì¶”ë¡  ëª¨ë“œ ON ì‹œ `gemini-2.5-pro` ëª¨ë¸ ì‚¬ìš©
- íŠ¹ì • ì¡°ê±´ì—ì„œ ìë™ìœ¼ë¡œ ì¶”ë¡  ëª¨ë“œë¡œ ì§„ì…

### ìë™ ì¶”ë¡  ëª¨ë“œ ì§„ì… ì¡°ê±´
| ì¡°ê±´ | ì˜ˆì‹œ |
|------|------|
| ë³µí•© ì§ˆì˜ (ì—¬ëŸ¬ ì£¼ì œ ê²°í•©) | "Aì™€ Bë¥¼ ë¹„êµí•´ì¤˜", "X, Y, Z ê°ê° ì„¤ëª…í•´ì¤˜" |
| ë¶„ì„ ìš”ì²­ | "ì›ì¸ì„ ë¶„ì„í•´ì¤˜", "ì¥ë‹¨ì  ë¶„ì„" |
| ë¹„êµ ìš”ì²­ | "ì°¨ì´ì ì´ ë­ì•¼?", "ì–´ë–¤ ê²Œ ë” ì¢‹ì•„?" |
| ëª…ì‹œì  ì„¤ëª… ìš”êµ¬ | "ìì„¸íˆ ì„¤ëª…í•´ì¤˜", "ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ì¤˜" |
| ìˆ˜í•™ì  ë¬¸ì œ | ê³„ì‚°, ìˆ˜ì‹, ë…¼ë¦¬ ë¬¸ì œ |
| ì–´ë ¤ìš´ ì£¼ì œ | ì „ë¬¸ ìš©ì–´, ë³µì¡í•œ ê°œë… |

### í•´ê²° ë°©ì•ˆ

#### 2.1 ì‚¬ì´ë“œë°”ì— ì¶”ë¡  ëª¨ë“œ ì„¤ì • ì¶”ê°€
```python
# component/sidebar.py

with st.sidebar.expander("Model Settings", expanded=True):
    # ê¸°ì¡´ ëª¨ë¸ ì„ íƒ
    model = st.selectbox(
        "Chat Model",
        options=["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"],
        index=0,
    )

    # ì¶”ë¡  ëª¨ë“œ í† ê¸€
    reasoning_mode = st.toggle(
        "ì¶”ë¡  ëª¨ë“œ (Reasoning Mode)",
        value=False,
        help="ë³µì¡í•œ ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸ì— gemini-2.5-pro ì‚¬ìš©",
    )

    auto_reasoning = st.toggle(
        "ìë™ ì¶”ë¡  ëª¨ë“œ ê°ì§€",
        value=True,
        help="ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì¶”ë¡  ëª¨ë“œ í™œì„±í™”",
    )
```

#### 2.2 ì¶”ë¡  ëª¨ë“œ ê°ì§€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
```python
# service/reasoning_detector.py (ì‹ ê·œ íŒŒì¼)

import re
from typing import Literal

REASONING_PATTERNS = [
    # ë¹„êµ/ë¶„ì„ í‚¤ì›Œë“œ
    r"ë¹„êµ|ë¶„ì„|ì°¨ì´ì |ì¥ë‹¨ì |pros.?cons",
    # ì„¤ëª… ìš”êµ¬
    r"ì™œ|ì–´ë–»ê²Œ|ì›ì¸|ì´ìœ |ë©”ì»¤ë‹ˆì¦˜|ì›ë¦¬",
    # ë‹¨ê³„ë³„ ì„¤ëª…
    r"ë‹¨ê³„ë³„|step.?by.?step|í•˜ë‚˜ì”©|ìˆœì„œëŒ€ë¡œ",
    # ë³µí•© ì§ˆì˜
    r"ê·¸ë¦¬ê³ |ë˜í•œ|ì¶”ê°€ë¡œ|ë¿ë§Œ.?ì•„ë‹ˆë¼",
    # ìˆ˜í•™/ë…¼ë¦¬
    r"\d+\s*[\+\-\*\/\=]|\b(ê³„ì‚°|ìˆ˜ì‹|ê³µì‹|ì¦ëª…|ë…¼ë¦¬)\b",
    # ì „ë¬¸ ë¶„ì„
    r"ì‹¬ì¸µ|ì‹¬í™”|ê¹Šì´|ìì„¸íˆ|ìƒì„¸íˆ|êµ¬ì²´ì ìœ¼ë¡œ",
]

CASUAL_PATTERNS = [
    # ê°íƒ„ì‚¬/ì¸ì‚¬
    r"^(ì˜¤í˜¸|ì•„í•˜|ê·¸ë ‡êµ¬ë‚˜|ì•Œê² |ë„¤|ì‘|ì•„|ì˜¤|ìŒ|í |ã…ã…|ã…‹ã…‹|ì•ˆë…•|ë°˜ê°€ì›Œ|ê³ ë§ˆì›Œ|ê°ì‚¬)",
    # ë‹¨ìˆœ ê¸ì •/ë¶€ì •
    r"^(ì¢‹ì•„|ì‹«ì–´|ê´œì°®|ê·¸ë˜|ëì–´|ì•Œì•˜ì–´|ì˜¤ì¼€ì´|ok|ã…‡ã…‹)",
    # ì§§ì€ ì‘ë‹µ (10ì ë¯¸ë§Œ)
    r"^.{1,10}$",
]


def detect_reasoning_need(user_input: str) -> Literal["reasoning", "casual", "normal"]:
    """ì§ˆë¬¸ ìœ í˜•ì„ ê°ì§€í•˜ì—¬ ì ì ˆí•œ ëª¨ë“œ ë°˜í™˜

    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥

    Returns:
        "reasoning": ì¶”ë¡  ëª¨ë“œ í•„ìš”
        "casual": ì¼ìƒì  ëŒ€í™” (íˆ´ ì‚¬ìš© ë¶ˆí•„ìš”)
        "normal": ì¼ë°˜ ëª¨ë“œ
    """
    # 1. ì¼ìƒì  ëŒ€í™” ì²´í¬ (ë¨¼ì € í™•ì¸)
    for pattern in CASUAL_PATTERNS:
        if re.search(pattern, user_input, re.IGNORECASE):
            return "casual"

    # 2. ì¶”ë¡  ëª¨ë“œ í•„ìš” ì²´í¬
    for pattern in REASONING_PATTERNS:
        if re.search(pattern, user_input, re.IGNORECASE):
            return "reasoning"

    return "normal"
```

#### 2.3 ReactGraphBuilderì—ì„œ ëª¨ë¸ ë™ì  ì „í™˜
```python
# service/react_graph.py

def __init__(
    self,
    api_key: str,
    model: str = "gemini-2.5-flash",
    reasoning_model: str = "gemini-2.5-pro",  # ì¶”ê°€
    reasoning_mode: bool = False,              # ì¶”ê°€
    auto_reasoning: bool = True,               # ì¶”ê°€
    # ... ê¸°ì¡´ íŒŒë¼ë¯¸í„°
):
    self.reasoning_model = reasoning_model
    self.reasoning_mode = reasoning_mode
    self.auto_reasoning = auto_reasoning

    # ì¶”ë¡ ìš© LLM ë³„ë„ ì´ˆê¸°í™”
    self._reasoning_llm = ChatGoogleGenerativeAI(
        model=reasoning_model,
        google_api_key=api_key,
        temperature=temperature,
    )

def _get_llm_for_context(self, user_input: str):
    """ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” LLM ë°˜í™˜"""
    if self.reasoning_mode:
        return self._reasoning_llm

    if self.auto_reasoning:
        mode = detect_reasoning_need(user_input)
        if mode == "reasoning":
            return self._reasoning_llm

    return self._llm
```

### ìˆ˜ì • ëŒ€ìƒ íŒŒì¼
| íŒŒì¼ | ìˆ˜ì • ë‚´ìš© |
|------|----------|
| `component/sidebar.py` | ì¶”ë¡  ëª¨ë“œ í† ê¸€ UI ì¶”ê°€ |
| `service/reasoning_detector.py` | ì‹ ê·œ íŒŒì¼ - ì¶”ë¡  ëª¨ë“œ ê°ì§€ ìœ í‹¸ë¦¬í‹° |
| `service/react_graph.py` | ì¶”ë¡ ìš© LLM ì´ˆê¸°í™”, ë™ì  ëª¨ë¸ ì„ íƒ |
| `app.py` | ì‚¬ì´ë“œë°” ì„¤ì •ì„ ReactGraphBuilderì— ì „ë‹¬ |

---

## 3. Tool Selector ê°œì„  - ì¼ìƒì  ì§ˆë¬¸ì— íˆ´ ë¯¸ì‚¬ìš©

### í˜„ìƒ
- "ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜" ê°™ì€ ê°íƒ„ì‚¬ì—ë„ Tool Selectorê°€ ì‹¤í–‰ë¨
- ëª¨ë“  ì§ˆì˜ì— ëŒ€í•´ ë¶ˆí•„ìš”í•˜ê²Œ íˆ´ì„ ê³ ë ¤í•˜ì—¬ ë¹„íš¨ìœ¨ì 

### í•´ê²° ë°©ì•ˆ

#### 3.1 Tool Selector í”„ë¡¬í”„íŠ¸ì— ê·œì¹™ ì¶”ê°€
```python
# prompt/selector/tool_selector.py

TOOL_SELECTOR_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ **ë‹¤ìŒì— ì‹¤í–‰í•  íˆ´ í•˜ë‚˜**ë¥¼ ì„ íƒí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬

| ë„êµ¬ | ì‚¬ìš© ì¡°ê±´ |
|------|----------|
| get_current_time | í˜„ì¬ ì‹œê°, ë‚ ì§œ, ì˜¤ëŠ˜ ê´€ë ¨ ì§ˆë¬¸ |
| web_search | ìµœì‹  ì •ë³´, ë‰´ìŠ¤, ì‹¤ì‹œê°„ ë°ì´í„°, "ê²€ìƒ‰í•´ì¤˜" |
| search_pdf_knowledge | "ë¬¸ì„œì—ì„œ", "íŒŒì¼ì—", PDF ê´€ë ¨ ì§ˆë¬¸ |
| reasoning | "ì™œ", "ì–´ë–»ê²Œ", "ë¹„êµ", "ë¶„ì„", ë³µí•© ì§ˆì˜, ë³µì¡í•œ ì¶”ë¡  |
| none | ë” ì´ìƒ íˆ´ì´ í•„ìš” ì—†ìŒ |

## ğŸš« íˆ´ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° (ì¤‘ìš”!)

ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì—ëŠ” **ë°˜ë“œì‹œ "none"ì„ ì„ íƒ**í•˜ì„¸ìš”:

1. **ì¼ìƒì  ëŒ€í™”/ì¸ì‚¬**: "ì•ˆë…•", "ê³ ë§ˆì›Œ", "ë°˜ê°€ì›Œ", "ì˜ê°€" ë“±
2. **ê°íƒ„ì‚¬/ë§ì¥êµ¬**: "ì˜¤í˜¸", "ê·¸ë ‡êµ¬ë‚˜", "ì•„í•˜", "ì•Œê² ì–´", "ë„¤", "ì‘" ë“±
3. **ë‹¨ìˆœ ê¸ì •/ë¶€ì •**: "ì¢‹ì•„", "ì‹«ì–´", "ê´œì°®ì•„", "ëì–´" ë“±
4. **ì§§ì€ ê°ì • í‘œí˜„**: "ã…ã…", "ã…‹ã…‹", "^^", ì´ëª¨ì§€ë§Œ ìˆëŠ” ê²½ìš°
5. **ëª…í™•í•œ í›„ì† ì§ˆë¬¸ ì—†ì´ ëë‚˜ëŠ” ë°œí™”**

ì´ëŸ° ì…ë ¥ì€ ì •ë³´ ê²€ìƒ‰ì´ë‚˜ ì¶”ë¡ ì´ í•„ìš” ì—†ìœ¼ë©°,
ìì—°ìŠ¤ëŸ½ê³  í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•˜ëŠ” ê²ƒì´ ë” ì ì ˆí•©ë‹ˆë‹¤.

## ê·œì¹™

1. **í•œ ë²ˆì— í•˜ë‚˜ì˜ íˆ´ë§Œ** ì„ íƒí•˜ì„¸ìš”
2. ì´ë¯¸ ì‹¤í–‰í•œ íˆ´ì€ ë‹¤ì‹œ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”
3. PDFê°€ ì—…ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ web_searchë³´ë‹¤ search_pdf_knowledge ìš°ì„ 
4. ì¶©ë¶„í•œ ì •ë³´ê°€ ëª¨ì˜€ìœ¼ë©´ "none" ì„ íƒ
5. **ì¼ìƒì  ëŒ€í™”ëŠ” ë¬´ì¡°ê±´ "none" ì„ íƒ**

## í˜„ì¬ ìƒíƒœ

- ì‚¬ìš©ì ì§ˆë¬¸: {user_input}
- ì´ë¯¸ ì‹¤í–‰í•œ íˆ´: {tool_history}
- í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´: {tool_results_summary}
- ì—…ë¡œë“œëœ PDF: {pdf_description}

## ì¶œë ¥ í˜•ì‹

ì„ íƒí•œ íˆ´ ì´ë¦„ë§Œ ì¶œë ¥ (ë”°ì˜´í‘œ ì—†ì´):
web_search
""".strip()
```

#### 3.2 Pre-filter ë¡œì§ ì¶”ê°€ (ì„ íƒì  ìµœì í™”)
```python
# service/react_graph.py

def _tool_selector_node(self, state: ChatState) -> dict:
    """Tool Selector ë…¸ë“œ: ë‹¤ìŒì— ì‹¤í–‰í•  íˆ´ ì„ íƒ"""

    # Pre-filter: ì¼ìƒì  ëŒ€í™”ëŠ” LLM í˜¸ì¶œ ì—†ì´ ë°”ë¡œ none ë°˜í™˜
    from service.reasoning_detector import detect_reasoning_need

    if detect_reasoning_need(state["user_input"]) == "casual":
        return {"current_tool": "none"}

    # ... ê¸°ì¡´ LLM í˜¸ì¶œ ë¡œì§ ...
```

### ìˆ˜ì • ëŒ€ìƒ íŒŒì¼
| íŒŒì¼ | ìˆ˜ì • ë‚´ìš© |
|------|----------|
| `prompt/selector/tool_selector.py` | ì¼ìƒì  ëŒ€í™” ê·œì¹™ ì¶”ê°€ |
| `service/react_graph.py` | Pre-filter ë¡œì§ ì¶”ê°€ (ì„ íƒì ) |

---

## 4. ì¼ìƒì  ëŒ€í™” ì²˜ë¦¬ ê°œì„ 

### í˜„ìƒ
- "ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜"ì— ëŒ€í•´ ê³¼ë„í•˜ê²Œ ë¶„ì„ì ì¸ ì‘ë‹µ ìƒì„±
- Response Generatorê°€ í˜•ì‹ì ì´ê³  ë”±ë”±í•œ ì‘ë‹µ ìƒì„±

### í•´ê²° ë°©ì•ˆ

#### 4.1 Response Generator í”„ë¡¬í”„íŠ¸ ê°œì„ 
```python
# prompt/response/response_generator.py

RESPONSE_GENERATOR_PROMPT = """
ë‹¹ì‹ ì€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìµœì¢… ì‘ë‹µì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‘ë‹µ ì›ì¹™

### ì¼ìƒì  ëŒ€í™”ì¸ ê²½ìš° (ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°)

ë§Œì•½ ìˆ˜ì§‘ëœ ì •ë³´ê°€ "ì—†ìŒ"ì´ê³  ì‚¬ìš©ì ì…ë ¥ì´ ë‹¤ìŒê³¼ ê°™ë‹¤ë©´:
- ì¸ì‚¬, ê°íƒ„ì‚¬, ë§ì¥êµ¬ ("ì•ˆë…•", "ì˜¤í˜¸", "ê·¸ë ‡êµ¬ë‚˜", "ì•Œê² ì–´" ë“±)
- ë‹¨ìˆœí•œ ê°ì • í‘œí˜„ ("ã…ã…", "ì¢‹ì•„", "ê³ ë§ˆì›Œ" ë“±)

**ì´ ê²½ìš°ì—ëŠ” ë¶„ì„ì´ë‚˜ ì„¤ëª… ì—†ì´ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.**

ì˜ˆì‹œ:
- "ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜" â†’ "ë„¤, ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š"
- "ê³ ë§ˆì›Œ" â†’ "ë³„ë§ì”€ì„ìš”! ë” ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”."
- "ì•ˆë…•" â†’ "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"

### ì •ë³´ ê¸°ë°˜ ì‘ë‹µì¸ ê²½ìš°

1. **êµ¬ì¡°í™”**: í•„ìš”ì‹œ ì œëª©, ëª©ë¡, í‘œ ë“± ì‚¬ìš©
2. **ì¶©ì‹¤í•œ ë‹µë³€**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ ë°˜ì˜
3. **ì˜ˆì‹œ í¬í•¨**: êµ¬ì²´ì ì¸ ì˜ˆì‹œë¡œ ì´í•´ë„ í–¥ìƒ
4. **ì¶œì²˜ ì–¸ê¸‰**: ì›¹ ê²€ìƒ‰/PDF ê²°ê³¼ì¸ ê²½ìš° ì¶œì²˜ ëª…ì‹œ

## í˜„ì¬ ìƒíƒœ

- ì‚¬ìš©ì ì§ˆë¬¸: {user_input}
- ìˆ˜ì§‘ëœ ì •ë³´: {collected_info}
- Result Processor ìš”ì•½: {processor_summary}

## ì¶œë ¥

ìµœì¢… ì‘ë‹µì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
ì¼ìƒì  ëŒ€í™”ì˜ ê²½ìš° í˜•ì‹ ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•˜ì„¸ìš”.
""".strip()
```

#### 4.2 ì¼ìƒì  ëŒ€í™” Fast-path êµ¬í˜„ (ì„ íƒì  ìµœì í™”)
```python
# service/react_graph.py

def invoke(self, user_input: str, ...) -> dict:
    """ê·¸ë˜í”„ ì‹¤í–‰"""

    # Fast-path: ì¼ìƒì  ëŒ€í™”ëŠ” ê·¸ë˜í”„ ì‹¤í–‰ ì—†ì´ ë°”ë¡œ ì‘ë‹µ
    from service.reasoning_detector import detect_reasoning_need

    if detect_reasoning_need(user_input) == "casual":
        # ê°„ë‹¨í•œ LLM í˜¸ì¶œë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
        response = self._llm.invoke([
            HumanMessage(content=f"""
ì‚¬ìš©ìê°€ "{user_input}"ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤.
ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ì§§ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë¶„ì„ì´ë‚˜ ì„¤ëª… ì—†ì´ìš”.
""")
        ])
        return {
            "text": response.content,
            "tool_history": [],
            "tool_results": {},
            "iteration": 0,
            "model_used": self.model_name,
            "summary": summary,
            "summary_history": summary_history or [],
            "is_casual": True,  # ì¼ìƒì  ëŒ€í™” í”Œë˜ê·¸
            "error": None,
        }

    # ... ê¸°ì¡´ ê·¸ë˜í”„ ì‹¤í–‰ ë¡œì§ ...
```

### ìˆ˜ì • ëŒ€ìƒ íŒŒì¼
| íŒŒì¼ | ìˆ˜ì • ë‚´ìš© |
|------|----------|
| `prompt/response/response_generator.py` | ì¼ìƒì  ëŒ€í™” ì‘ë‹µ ì›ì¹™ ì¶”ê°€ |
| `service/react_graph.py` | Fast-path êµ¬í˜„ (ì„ íƒì ) |

---

## 5. êµ¬í˜„ ìš°ì„ ìˆœìœ„

| ìˆœìœ„ | í•­ëª© | ë‚œì´ë„ | ì˜í–¥ë„ |
|------|------|--------|--------|
| 1 | Tool Selector í”„ë¡¬í”„íŠ¸ ê°œì„  | ë‚®ìŒ | ë†’ìŒ |
| 2 | Response Generator í”„ë¡¬í”„íŠ¸ ê°œì„  | ë‚®ìŒ | ë†’ìŒ |
| 3 | Token Usage ì¶”ì  êµ¬í˜„ | ì¤‘ê°„ | ì¤‘ê°„ |
| 4 | ì¶”ë¡  ëª¨ë“œ ì‚¬ì´ë“œë°” UI | ì¤‘ê°„ | ì¤‘ê°„ |
| 5 | reasoning_detector.py êµ¬í˜„ | ì¤‘ê°„ | ë†’ìŒ |
| 6 | Fast-path ìµœì í™” | ë†’ìŒ | ë‚®ìŒ |

---

## 6. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### 6.1 Token Usage í…ŒìŠ¤íŠ¸
```python
def test_token_usage_tracking():
    """í† í° ì‚¬ìš©ëŸ‰ì´ ì •ìƒì ìœ¼ë¡œ ì¶”ì ë˜ëŠ”ì§€ í™•ì¸"""
    # Given: ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡
    # When: ì‘ë‹µ ìˆ˜ì‹ 
    # Then: token_usageê°€ 0ë³´ë‹¤ ì»¤ì•¼ í•¨
```

### 6.2 ì¶”ë¡  ëª¨ë“œ í…ŒìŠ¤íŠ¸
```python
def test_auto_reasoning_detection():
    """ì¶”ë¡  ëª¨ë“œ ìë™ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    assert detect_reasoning_need("Aì™€ Bë¥¼ ë¹„êµí•´ì¤˜") == "reasoning"
    assert detect_reasoning_need("ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜") == "casual"
    assert detect_reasoning_need("ë‚ ì”¨ ì–´ë•Œ?") == "normal"
```

### 6.3 ì¼ìƒì  ëŒ€í™” í…ŒìŠ¤íŠ¸
```python
def test_casual_conversation_no_tool():
    """ì¼ìƒì  ëŒ€í™”ì—ì„œ íˆ´ì´ í˜¸ì¶œë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸"""
    # Given: "ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜" ì…ë ¥
    # When: ì‘ë‹µ ìˆ˜ì‹ 
    # Then: tool_historyê°€ ë¹„ì–´ìˆì–´ì•¼ í•¨
```

---

## 7. ì˜ˆìƒ ê²°ê³¼

### Before
```
ì‚¬ìš©ì: ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜

ë´‡: í˜„ì¬ ìƒí™© ë¶„ì„
ì‚¬ìš©ì ì§ˆë¬¸: ì‚¬ìš©ìë‹˜ê»˜ì„œ "ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜"ë¼ê³  ë§ì”€í•´ì£¼ì…¨ìŠµë‹ˆë‹¤...
(ì¥í™©í•œ ë¶„ì„ í…ìŠ¤íŠ¸)
```

### After
```
ì‚¬ìš©ì: ì˜¤í˜¸ ê·¸ë ‡êµ¬ë‚˜

ë´‡: ë„¤, ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š
```
