import streamlit as st
from domain.message import Message


def format_summary_card(summary_entry: dict) -> str:
    """ìš”ì•½ íˆìŠ¤í† ë¦¬ ì—”íŠ¸ë¦¬ë¥¼ ë§ˆí¬ë‹¤ìš´ ì¹´ë“œ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

    Phase 03-3-2: excluded_turns í‘œì‹œ ì§€ì›
    Phase 03-3-3: Turn 1 ì œì™¸ í‘œì‹œ ìˆ˜ì •
    """
    turns = summary_entry.get("turns", [])
    excluded = summary_entry.get("excluded_turns", [])
    summarized = summary_entry.get("summarized_turns", turns)  # ì‹¤ì œ ìš”ì•½ëœ í„´

    # í„´ ë²”ìœ„ í‘œì‹œ: "Turn 1-3" ë˜ëŠ” "Turn 1, 3, 4"
    if turns:
        if len(turns) > 1 and turns == list(range(min(turns), max(turns) + 1)):
            # ì—°ì† ë²”ìœ„
            turns_str = f"{min(turns)}-{max(turns)}"
        else:
            turns_str = ", ".join(str(t) for t in turns)
    else:
        turns_str = "?"

    summary = summary_entry.get("summary", "")

    # excluded í„´ì´ ìˆìœ¼ë©´ í‘œì‹œ (casual í„´)
    if excluded:
        excluded_str = f"\n*({', '.join(map(str, sorted(excluded)))}í„´ casual)*"
    else:
        excluded_str = ""

    return f"**Turn {turns_str}**{excluded_str}\n\n{summary}"


def _handle_streaming_response(on_stream: callable, user_input: str) -> dict:
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬"""
    response_placeholder = st.empty()
    status_placeholder = st.empty()
    thought_placeholder = st.empty()  # Phase 03-5

    full_response = ""
    full_thought = ""  # Phase 03-5
    tool_calls = []
    metadata = {}

    for chunk in on_stream(user_input):
        chunk_type = chunk.get("type")

        if chunk_type == "token":
            full_response += chunk.get("content", "")
            response_placeholder.markdown(full_response + "â–Œ")

        elif chunk_type == "thought":
            # Phase 03-5: ì‚¬ê³  ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ
            full_thought += chunk.get("content", "")
            thought_placeholder.caption("ğŸ§  ì‚¬ê³  ì¤‘...")

        elif chunk_type == "tool_call":
            tool_name = chunk.get("name", "unknown")
            status_placeholder.caption(f"ğŸ”§ {tool_name} í˜¸ì¶œ ì¤‘...")
            tool_calls.append({"name": tool_name, "result": None})

        elif chunk_type == "tool_result":
            tool_name = chunk.get("name")
            for tc in tool_calls:
                if tc["name"] == tool_name and tc["result"] is None:
                    tc["result"] = chunk.get("content", "")
                    break
            status_placeholder.empty()

        elif chunk_type == "done":
            metadata = chunk.get("metadata", {})
            status_placeholder.empty()
            thought_placeholder.empty()

    response_placeholder.markdown(full_response)

    # Phase 03-5: ì‚¬ê³  ê³¼ì • expander (done í›„)
    thought_process = full_thought or metadata.get("thought_process", "")
    if thought_process:
        with st.expander("ğŸ§  ëª¨ë¸ì˜ ì‚¬ê³  ê³¼ì •", expanded=False):
            st.markdown(thought_process)

    return {
        "text": full_response,
        "tool_calls": tool_calls,
        "tool_results": metadata.get("tool_results", {}),
        "model_used": metadata.get("model_used", ""),
        "summary": metadata.get("summary", ""),
        "summary_history": metadata.get("summary_history", []),
        "input_tokens": metadata.get("input_tokens", 0),
        "output_tokens": metadata.get("output_tokens", 0),
        "normal_turn_ids": metadata.get("normal_turn_ids", []),
        "normal_turn_count": metadata.get("normal_turn_count", 0),
        "thought_process": thought_process,  # Phase 03-5
        # Phase 04: metadata pass-through
        "mode": metadata.get("mode", "normal"),
        "graph_path": metadata.get("graph_path", []),
        "summary_triggered": metadata.get("summary_triggered", False),
        "is_casual": metadata.get("is_casual", False),
    }


def _mode_badge(mode: str) -> str:
    """ëª¨ë“œë³„ ì´ëª¨ì§€ + ë¼ë²¨"""
    badges = {
        "casual": "ğŸŸ¢ casual",
        "normal": "ğŸ”µ normal",
        "reasoning": "ğŸŸ£ reasoning",
    }
    return badges.get(mode, f"âšª {mode}")


def _format_graph_path(path: list[str]) -> str:
    """ê·¸ë˜í”„ ê²½ë¡œë¥¼ í™”ì‚´í‘œ í˜•ì‹ìœ¼ë¡œ í¬ë§·"""
    if not path:
        return "N/A"
    return " â†’ ".join(path) + " â†’ END"


def _render_turn_metadata(msg: Message) -> None:
    """í„´ ì‹¤í–‰ ë©”íƒ€ë°ì´í„° íŒ¨ë„ ë Œë”ë§"""
    with st.expander("ğŸ“Š ì‹¤í–‰ ìƒì„¸", expanded=False):
        col1, col2, col3 = st.columns(3)
        col1.metric("Turn", msg.turn_id)
        col2.markdown(f"**{_mode_badge(msg.mode)}**")
        col3.caption(f"ğŸ¤– {msg.model_used or 'N/A'}")

        st.markdown(f"**Graph Path:** `{_format_graph_path(msg.graph_path)}`")

        if msg.summary_triggered:
            st.markdown("ğŸ“‹ **Summary:** íŠ¸ë¦¬ê±°ë¨")

        if msg.function_calls:
            names = [fc.get('name', 'unknown') for fc in msg.function_calls]
            st.markdown(f"ğŸ”§ **Tools:** {', '.join(names)} ({len(names)}ê°œ)")

        if msg.thinking_budget > 0:
            st.markdown(f"ğŸ§  **Thinking:** budget {msg.thinking_budget}")

        st.caption(f"ğŸ“ˆ Tokens: {msg.input_tokens} in / {msg.output_tokens} out")


def render_chat_tab(
    on_send: callable,
    on_stream: callable = None,
    messages: list[Message] = None,
    summary_history: list[dict] = None,
    turn_count: int = None,
    use_streaming: bool = True,
) -> None:
    if messages is None:
        messages = []

    # í„´ ìˆ˜ ê³„ì‚° (ì „ë‹¬ë˜ì§€ ì•Šì€ ê²½ìš° user ë©”ì‹œì§€ ìˆ˜ë¡œ ê³„ì‚°)
    if turn_count is None:
        turn_count = len([m for m in messages if m.role == "user"])

    # í—¤ë” + í„´ ë²ˆí˜¸ í‘œì‹œ
    col1, col2 = st.columns([4, 1])
    with col1:
        st.header("Chat")
    with col2:
        st.metric("Turn", turn_count)

    # 2-Column ë ˆì´ì•„ì›ƒ (3:1 ë¹„ìœ¨)
    if summary_history is None:
        summary_history = []

    chat_col, summary_col = st.columns([3, 1])

    # ì™¼ìª½ ì»¬ëŸ¼: ì±„íŒ… ë©”ì‹œì§€
    with chat_col:
        chat_container = st.container()

        with chat_container:
            for msg in messages:
                role = "user" if msg.role == "user" else "assistant"
                with st.chat_message(role):
                    st.markdown(msg.content)

                    if msg.role == "assistant":
                        # íˆ´ ì‚¬ìš© ì •ë³´ Expander (Phase 02)
                        if msg.function_calls or msg.tool_results:
                            with st.expander("ğŸ”§ íˆ´ ì‚¬ìš© ì •ë³´", expanded=False):
                                if msg.function_calls:
                                    tool_names = [fc.get("name", "unknown") for fc in msg.function_calls]
                                    st.markdown(f"**ì„ íƒëœ íˆ´:** {', '.join(tool_names)}")
                                    st.divider()

                                if msg.tool_results:
                                    for tool_name, result in msg.tool_results.items():
                                        st.markdown(f"ğŸ“Œ **[{tool_name}]**")
                                        if isinstance(result, dict):
                                            st.json(result)
                                        else:
                                            st.code(str(result), language=None)

                        # Phase 04: ì‹¤í–‰ ìƒì„¸ ë©”íƒ€ë°ì´í„°
                        _render_turn_metadata(msg)

    # ì˜¤ë¥¸ìª½ ì»¬ëŸ¼: ìš”ì•½ íˆìŠ¤í† ë¦¬
    with summary_col:
        st.markdown("#### ğŸ“‹ Summary")
        if summary_history:
            for entry in summary_history:
                with st.container(border=True):
                    st.markdown(format_summary_card(entry))
        else:
            st.caption("ëŒ€í™” ìš”ì•½ì´ 3í„´ë§ˆë‹¤ ìƒì„±ë©ë‹ˆë‹¤.")

    # ì±„íŒ… ì…ë ¥ì°½ (ì»¬ëŸ¼ ì™¸ë¶€ì— ë°°ì¹˜)
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

    if user_input:
        with chat_col:
            with st.chat_message("user"):
                st.markdown(user_input)

            with st.chat_message("assistant"):
                if use_streaming and on_stream:
                    response = _handle_streaming_response(on_stream, user_input)
                else:
                    with st.spinner("Thinking..."):
                        response = on_send(user_input)

                if response:
                    # ìŠ¤íŠ¸ë¦¬ë°ì—ì„œëŠ” í…ìŠ¤íŠ¸ ì´ë¯¸ í‘œì‹œë¨, fallbackë§Œ í‘œì‹œ
                    if not (use_streaming and on_stream):
                        st.markdown(response.get("text", ""))

                    # ë„êµ¬ ì •ë³´
                    if response.get("tool_calls"):
                        with st.expander("ğŸ”§ íˆ´ ì‚¬ìš© ì •ë³´", expanded=False):
                            for tool in response["tool_calls"]:
                                st.markdown(f"**{tool['name']}**")
                                if tool.get("result"):
                                    st.code(tool["result"][:500], language=None)

                    # ëª¨ë¸ ìƒì„¸
                    if response.get("model_used"):
                        with st.expander("Details", expanded=False):
                            st.caption(f"Model: {response['model_used']}")
                            st.caption(f"Tokens: {response.get('input_tokens', 0)} in / {response.get('output_tokens', 0)} out")
